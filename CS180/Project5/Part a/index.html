<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>5a: The Power of Diffusion Models!</title>
    <style>
        body {
            font-family: 'Helvetica Neue', Arial, sans-serif;
            background-color: #f5f5f5;
            color: #333;
            margin: 0;
            padding: 0;
        }
        header, h1, h2, h3 {
            text-align: center;
            margin: 20px 0;
        }
        header {
            background-color: #4a90e2;
            color: white;
            padding: 40px 0;
            margin-bottom: 40px;
        }
        h1 {
            font-size: 36px;
            margin-bottom: 10px;
        }
        h2 {
            color: #4a90e2;
            margin-top: 60px;
            margin-bottom: 20px;
        }
        h3 {
            color: #333;
            margin-top: 40px;
            margin-bottom: 15px;
        }
        p {
            line-height: 1.6;
            max-width: 800px;
            margin: 0 auto 20px auto;
            padding: 0 20px;
        }
        img {
            display: block;
            max-width: 100%;
            height: auto;
            margin: 20px auto;
            border-radius: 8px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        .image-row {
            display: flex;
            flex-wrap: wrap;
            justify-content: center;
            margin: 20px 0;
        }
        .image-row img {
            width: 45%;
            margin: 10px;
        }
        footer {
            text-align: center;
            padding: 20px 0;
            background-color: #4a90e2;
            color: white;
            margin-top: 60px;
        }
        @media (max-width: 768px) {
            h1 {
                font-size: 28px;
            }
            .image-row img {
                width: 90%;
            }
        }
    </style>
</head>
<body>

<header>
    <h1>5a: The Power of Diffusion Models!</h1>
    <p>An exploration of the capabilities and applications of diffusion models</p>
</header>

<h2>Part 0: Setup</h2>

<p>In this part, I gained access to DeepFloyd, obtained some pre-embedded text prompts, and downloaded the precomputed text embeddings. For the three text prompts provided, I displayed the caption and the output of the model with <code>num_inference_steps</code> values equal to 10, 20, and 40. Here are the results:</p>

<!-- Insert 3 images -->
<img src="image1.png" alt="Result for num_inference_steps=10">
<img src="image2.png" alt="Result for num_inference_steps=20">
<img src="image3.png" alt="Result for num_inference_steps=40">

<p>From the results, we can see that with 10 steps the image is noisy, and there are not any obvious differences between 20 and 40. The random seed used is 180.</p>

<h2>Part 1: Sampling Loops</h2>

<h3>1.1 Forward Process</h3>

<p>First, I implemented the forward process, which is the <code>forward(im, t)</code> function (adds random noise to the image at different levels). The test image at noise levels 250, 500, and 750 are shown below:</p>

<!-- Insert 1 image -->
<img src="forward_process.png" alt="Forward Process at Different Noise Levels">

<h3>1.2 Gaussian Blur Filtering</h3>

<p>Then, I tried using Gaussian blur filtering to remove the noise. The result is shown below:</p>

<!-- Insert image -->
<img src="gaussian_blur.png" alt="Result of Gaussian Blur Filtering">

<h3>1.3 One-Step Denoising</h3>

<p>I asked the model to implement one-step denoising on the test image with noise levels at 250, 500, and 750. The results are shown below:</p>

<!-- Insert image -->
<img src="one_step_denoising.png" alt="One-Step Denoising Results">

<h3>1.4 Multi-Step Denoising</h3>

<p>I implemented denoising with multiple steps. At each step, the model estimates the noise and the original image, allowing us to iteratively obtain a more accurate denoised image. The result is shown below:</p>

<!-- Insert image -->
<img src="multi_step_denoising.png" alt="Multi-Step Denoising Results">

<h3>1.5 Image Generation from Scratch</h3>

<p>I used the model to generate images from scratch. Here are five images generated:</p>

<!-- Insert image -->
<img src="generated_images.png" alt="Images Generated from Scratch">

<h3>1.6 Classifier-Free Guidance (CFG)</h3>

<p>To improve the images generated by the model, I applied Classifier-Free Guidance (CFG). Instead of using the noise predicted by the model directly at each step, I adjusted it by adding the difference from the unconditional prompt noise. The results are shown below:</p>

<!-- Insert image -->
<img src="cfg_results.png" alt="Classifier-Free Guidance Results">

<p>Interestingly, the results of CFG are mostly human faces, possibly because the training data predominantly features human faces.</p>

<h3>1.7 Denoising with Different Noise Levels</h3>

<p>I took the test image, added noise to it, and then denoised it. I experimented with different extents of noise, setting <code>i_start</code> to 1, 3, 5, 7, 10, and 20. The results are shown below:</p>

<!-- Insert image -->
<img src="denoising_different_noise_levels.png" alt="Denoising with Different Noise Levels">

<p>I also applied this method to my own images. The results are shown below:</p>

<!-- Insert 2 images -->
<div class="image-row">
    <img src="my_image_denoised1.png" alt="My Image Denoised - 1">
    <img src="my_image_denoised2.png" alt="My Image Denoised - 2">
</div>

<h3>1.7.1 Additional Images</h3>

<p>Besides the test image and my own images, I applied the method to a web image and two hand-drawn images. The results are shown below:</p>

<!-- Insert images -->
<div class="image-row">
    <img src="web_image_denoised.png" alt="Web Image Denoised">
    <img src="hand_drawn_image1.png" alt="Hand-Drawn Image Denoised - 1">
    <img src="hand_drawn_image2.png" alt="Hand-Drawn Image Denoised - 2">
</div>

<h3>1.7.2 Inpainting</h3>

<p>I used the same procedure to implement inpainting, following the RePaint paper. Given an image and a binary mask <code>m</code>, we can create a new image that retains the original content where <code>m</code> is 0, and generates new content where <code>m</code> is 1. The results are shown below, including the test image and two of my own images:</p>

<!-- Insert 6 images -->
<div class="image-row">
    <img src="inpainting_test_image.png" alt="Inpainting Result - Test Image">
    <img src="inpainting_my_image1.png" alt="Inpainting Result - My Image 1">
    <img src="inpainting_my_image2.png" alt="Inpainting Result - My Image 2">
</div>

<h3>1.7.3 SDEdit with Text Prompt</h3>

<p>I applied SDEdit, guiding the projection with a text prompt. The test image was prompted with "a photo of a rocket". The result is shown below:</p>

<!-- Insert image -->
<img src="sdedit_rocket.png" alt="SDEdit Result - Rocket">

<p>Applied to my own images:</p>

<!-- Insert 2 images -->
<div class="image-row">
    <img src="sdedit_my_image1.png" alt="SDEdit Result - My Image 1">
    <img src="sdedit_my_image2.png" alt="SDEdit Result - My Image 2">
</div>

<h3>1.8 Creating Optical Illusions with Diffusion Models</h3>

<p>I created optical illusions using diffusion models. In this part, I generated an image that looks like "an oil painting of people around a campfire", but when flipped upside down reveals "an oil painting of an old man". The result is shown below:</p>

<!-- Insert image -->
<img src="optical_illusion1.png" alt="Optical Illusion - Campfire and Old Man">

<p>Other results are shown below:</p>

<!-- Insert 2 images -->
<div class="image-row">
    <img src="optical_illusion2.png" alt="Optical Illusion - Image 2">
    <img src="optical_illusion3.png" alt="Optical Illusion - Image 3">
</div>

<h3>1.9 Factorized Diffusion and Hybrid Images</h3>

<p>In this part, I implemented Factorized Diffusion and created hybrid images, similar to those in Project 2. The results are shown below:</p>

<!-- Insert images -->
<img src="hybrid_images.png" alt="Hybrid Images with Factorized Diffusion">

<footer>
    <p>&copy; 2023 Fun With Diffusion Models</p>
</footer>

</body>
</html>
